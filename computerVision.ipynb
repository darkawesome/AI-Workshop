{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8133a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch pillow jupyter torchvision numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1385f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize gpu if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('You are using {device}'.format(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41626f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters / specifics to tune our neural network\n",
    "batch_size = 32 # number of inputs into neural network\n",
    "learning_rate = 0.001      # lr: the speed at which your network \"learns\"\n",
    "\n",
    "# the list of cifar10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c80a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the dataset CIFAR10\n",
    "\n",
    "# transforming the data to be interpretted by network easier\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# training data\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# test data\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65358bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two convolutional layers to customize\n",
    "def three_channel_conv1(image): \n",
    "    if isinstance(image,(np.ndarray, np.generic)):\n",
    "        image = torch.from_numpy(image)\n",
    "    c = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=4, stride=1)\n",
    "    d = nn.Dropout(.2)\n",
    "    mp = nn.MaxPool2d(2)\n",
    "    img = image\n",
    "    out = c(img)\n",
    "    out = d(out)\n",
    "    out = mp(out)\n",
    "    return out\n",
    "\n",
    "def three_channel_conv2(image, dropout=.1, maxpool=2, kernelSize=4, kernelStride=1): \n",
    "    \n",
    "    if isinstance(image, (np.ndarray, np.generic) ):\n",
    "        image = torch.from_numpy(image)\n",
    "    c = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=kernelSize, stride=kernelStride)\n",
    "    d = nn.Dropout(dropout)\n",
    "    mp = nn.MaxPool2d(maxpool)\n",
    "    out = c(image)\n",
    "    return out\n",
    "\n",
    "# visualize convolutional layers output\n",
    "def display_dataset(dataset, num_of_images=12, list_of_convs=[]):    \n",
    "    cols = 4\n",
    "    t = transforms.ToPILImage()\n",
    "    rows = int(math.ceil((num_of_images/4)))\n",
    "    fig_list = []\n",
    "    image_grid_list = []\n",
    "    for i in range(len(list_of_convs)+1):\n",
    "        fig_list.append(plt.figure(figsize=(6.0, 6.0)))\n",
    "        image_grid_list.append(ImageGrid(fig_list[i], 111, nrows_ncols=(rows, cols),\n",
    "                     axes_pad=0.1))\n",
    "    \n",
    "    for j in range(num_of_images):\n",
    "        reg_img = dataset[j][0]\n",
    "        image_grid_list[0][j].imshow(t(reg_img))\n",
    "        \n",
    "    for i in range(len(list_of_convs)):\n",
    "        for j in range(num_of_images):\n",
    "            img = dataset[j][0]\n",
    "            img = list_of_convs[i](img)\n",
    "            image_grid_list[i+1][j].imshow(t(img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dataset\n",
    "display_dataset(trainset, list_of_convs=[three_channel_conv1, three_channel_conv2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91512a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# uses GPU if available\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f226135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula for calculating how correct the network is\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# how we decide to improve the network\n",
    "# adam is the current state of the art optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# load dataset if you want to, comment out if you don't want to\n",
    "net.load_state_dict(torch.load('./nets/cifar10-best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d015947",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 0.2\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    curr_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        curr_loss += loss.item()\n",
    "        if i % 500 == 0:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {curr_loss / 2000:.3f}')\n",
    "            curr_loss = 0.0\n",
    "        \n",
    "            if curr_loss < best_loss and i != 0:\n",
    "                best_loss = curr_loss\n",
    "                # torch.save(net.state_dict(), './nets/cifar10-{loss}'.format(loss=curr_loss))\n",
    "                \n",
    "                # make sure you load dataset if you want to run this as it will overwrite the previous weights\n",
    "                torch.save(net.state_dict(), './nets/cifar10-best'.format(loss=curr_loss))\n",
    "                print('saving best model')\n",
    "                \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a050b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
